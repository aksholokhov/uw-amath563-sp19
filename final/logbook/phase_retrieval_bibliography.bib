
@article{Zheng2018RelaxAndSplit,
abstract = {We develop and analyze a new `relax-and-split' (RS) approach for compositions of separable nonconvex nonsmooth functions with linear maps. RS uses a relaxation technique together with partial minimization, and brings classic techniques including direct factorization, matrix decompositions, and fast iterative methods to bear on nonsmooth nonconvex problems. We also extend the approach to trimmed nonconvex-composite formulations; the resulting Trimmed RS (TRS) can fit models while detecting outliers in the data. We then test RS and TRS on a diverse set of applications: (1) phase retrieval, (2) stochastic shortest path problems, (3) semi-supervised classification, and (4) new clustering approaches. RS/TRS can be applied to models with very weak functional assumptions, are easy to implement, competitive with existing methods, and enable a new level of modeling formulations to be put forward to address emerging challenges in the mathematical sciences.},
archivePrefix = {arXiv},
arxivId = {1802.02654},
author = {Zheng, Peng and Aravkin, Aleksandr},
eprint = {1802.02654},
file = {:Users/aksholokhov/Documents/Papers/Zheng, Aravkin/2018/Unknown/Zheng, Aravkin - 2018 - Relax-and-split method for nonsmooth nonconvex problems.pdf:pdf},
month = {feb},
pages = {1--38},
title = {{Relax-and-split method for nonsmooth nonconvex problems}},
url = {http://arxiv.org/abs/1802.02654},
volume = {1},
year = {2018}
}

@article{Duchi2017PhaseRetrival,
abstract = {We develop procedures, based on minimization of the composition {\$}f(x) = h(c(x)){\$} of a convex function {\$}h{\$} and smooth function {\$}c{\$}, for solving random collections of quadratic equalities, applying our methodology to phase retrieval problems. We show that the prox-linear algorithm we develop can solve phase retrieval problems---even with adversarially faulty measurements---with high probability as soon as the number of measurements {\$}m{\$} is a constant factor larger than the dimension {\$}n{\$} of the signal to be recovered. The algorithm requires essentially no tuning---it consists of solving a sequence of convex problems---and it is implementable without any particular assumptions on the measurements taken. We provide substantial experiments investigating our methods, indicating the practical effectiveness of the procedures and showing that they succeed with high probability as soon as {\$}m / n \backslashge 2{\$} when the signal is real-valued.},
archivePrefix = {arXiv},
arxivId = {1705.02356},
author = {Duchi, John C. and Ruan, Feng},
eprint = {1705.02356},
file = {:Users/aksholokhov/Documents/Papers/Duchi, Ruan/2017/Unknown/Duchi, Ruan - 2017 - Solving (most) of a set of quadratic equalities Composite optimization for robust phase retrieval.pdf:pdf},
mendeley-groups = {Phase Retrieval},
number = {2},
pages = {1--55},
title = {{Solving (most) of a set of quadratic equalities: Composite optimization for robust phase retrieval}},
url = {http://arxiv.org/abs/1705.02356},
year = {2017}
}

@article{Parikh2014,
abstract = {Thismonograph is about a class of optimization algorithms called prox- imal algorithms.Much like Newton's method is a standard tool for solv- ing unconstrained smooth optimization problems of modest size, proxi- mal algorithms can be viewed as an analogous tool for nonsmooth, con- strained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical al- gorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed- form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpreta- tions of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
archivePrefix = {arXiv},
arxivId = {1502.03175},
author = {Parikh, Neal and Boyd, Stephen},
doi = {10.1561/2400000003},
eprint = {1502.03175},
file = {:Users/aksholokhov/Documents/Papers/Parikh, Boyd/2014/Foundations and Trends{\textregistered} in Optimization/Parikh, Boyd - 2014 - Proximal Algorithms.pdf:pdf},
isbn = {9781601987167},
issn = {2167-3888},
journal = {Foundations and Trends{\textregistered} in Optimization},
mendeley-groups = {Mathematics/Optimization/Continuous Optimisation/Proximal Methods},
number = {3},
pages = {127--239},
title = {{Proximal Algorithms}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-optimization/OPT-003},
volume = {1},
year = {2014}
}

